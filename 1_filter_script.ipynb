{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ee31e7",
   "metadata": {},
   "source": [
    "## 1. Select english sentences from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23720d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import spacy\n",
    "from langdetect import detect, DetectorFactory, detect_langs\n",
    "from polyglot.detect import Detector\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47989a",
   "metadata": {},
   "source": [
    "### 1.1 Delete duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f57216",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/dataset_cleand-1.csv\", names=['id', 'native', 'language', 'text'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24adf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x : ' '.join(x.splitlines()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb92e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>native</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>[{'language': 'Spanish', 'level': 45, 'profici...</td>\n",
       "      <td>Je suis Monique 58 ans, de Metz dans le Nord-E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>Hi there:) I live in Tokyo. I have been learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish&lt;br/&gt;Catalan</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>Hi everyone!  I'm looking for a language excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>[{'language': 'German', 'level': 19.2857142857...</td>\n",
       "      <td>Wuieres aprender español? Yo te puedo ayudar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Marathi&lt;br/&gt;Hindi</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>I am second year undergraduate student from Mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               native                                           language  \\\n",
       "0   0               French  [{'language': 'Spanish', 'level': 45, 'profici...   \n",
       "1   1             Japanese  [{'language': 'English', 'level': 45, 'profici...   \n",
       "2   2  Spanish<br/>Catalan  [{'language': 'English', 'level': 45, 'profici...   \n",
       "3   3              Spanish  [{'language': 'German', 'level': 19.2857142857...   \n",
       "4   4    Marathi<br/>Hindi  [{'language': 'English', 'level': 45, 'profici...   \n",
       "\n",
       "                                                text  \n",
       "0  Je suis Monique 58 ans, de Metz dans le Nord-E...  \n",
       "1  Hi there:) I live in Tokyo. I have been learni...  \n",
       "2  Hi everyone!  I'm looking for a language excha...  \n",
       "3       Wuieres aprender español? Yo te puedo ayudar  \n",
       "4  I am second year undergraduate student from Mu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45637801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Length: 82645\n",
      "New Length: \t28936\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates\n",
    "print(f'Orginal Length: {len(data)}')\n",
    "data = data.drop_duplicates(['native','language','text'])\n",
    "print(f'New Length: \\t{len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfcb596",
   "metadata": {},
   "source": [
    "### 1.2 use langdetect to extract english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f3d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warning\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b71c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67bf173c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x21d6c00fb50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup langdetect\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2676aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectorFactory.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ccf56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25706/25706 [10:58<00:00, 39.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = pd.read_csv(\"./data/english_only.csv\", encoding='utf-8')\n",
    "dataset = csv_file[['id','native','language','text']]\n",
    "original_datset = copy.deepcopy(dataset)\n",
    "\n",
    "c = 0\n",
    "filtered_dataset = pd.DataFrame()\n",
    "\n",
    "# loop through dataset, create a dataset with only english sentences...\n",
    "# ...according to some probability\n",
    "for i in tqdm(range(len(dataset['text']))):\n",
    "    splitted_text = tokenize.sent_tokenize(dataset['text'][i])\n",
    "    english_sent = []\n",
    "    for sent in splitted_text:\n",
    "        try:\n",
    "            langs = detect_langs(sent)\n",
    "            has_key = False\n",
    "            lang_index = 0\n",
    "            for l in range(len(langs)):\n",
    "                if langs[l].lang == \"en\":\n",
    "                    has_key = True\n",
    "                    lang_index = l\n",
    "                    break\n",
    "            if has_key and langs[lang_index].prob > 0.9:\n",
    "                english_sent.append(sent)\n",
    "        except:\n",
    "            pass\n",
    "    if len(english_sent) != 0:\n",
    "        dataset['text'][i] = \" \".join(english_sent)\n",
    "        # print(dataset['text'][i] ==  \" \".join(english_sent))\n",
    "        filtered_dataset = pd.concat([filtered_dataset, pd.DataFrame(dataset.iloc[[i]])])\n",
    "        c += 1  \n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0193a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset.to_csv('./data/english_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b65e4",
   "metadata": {},
   "source": [
    "### 1.3 use polyglot to further filter for english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90224996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is reliable: True\n",
      "Language 1: name: Italian     code: it       confidence:  55.0 read bytes:   593\n",
      "Language 2: name: English     code: en       confidence:  44.0 read bytes:  1067\n",
      "Language 3: name: un          code: un       confidence:   0.0 read bytes:     0\n"
     ]
    }
   ],
   "source": [
    "# Test detector\n",
    "text_content = \"Hello. I'm looking for language partners for practice my English. I can help you with Italian of course. I wish to know new cultures. Ciao. Sto cercando dei partners linguistici per parlare inglese. Io posso aiutare a migliorare l'italiano. Desidero conoscere nuove culture.\"\n",
    "#print(detect_langs(text_content))\n",
    "print(Detector(text_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d748c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.detect.base import logger as polyglot_logger\n",
    "polyglot_logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7d3efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25706/25706 [00:30<00:00, 851.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset_polyg = pd.DataFrame()\n",
    "c = 0\n",
    "\n",
    "for i in tqdm(range(len(dataset['text']))):\n",
    "    try: \n",
    "        langss = Detector(dataset['text'][i])\n",
    "        langs = langss.languages\n",
    "        has_key = False\n",
    "        lang_index = 0\n",
    "        for l in range(len(langs)):\n",
    "            if langs[l].code == \"en\":\n",
    "                has_key = True\n",
    "                lang_index = l\n",
    "                break\n",
    "        \n",
    "        if has_key and langs[lang_index].confidence > 0.99:\n",
    "            filtered_dataset_polyg = pd.concat([filtered_dataset_polyg, pd.DataFrame(dataset.iloc[[i]])])\n",
    "            c += 1\n",
    "    except:\n",
    "        pass\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7a8199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>native</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>Hi there:) I live in Tokyo. I have been learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish&lt;br/&gt;Catalan</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>I'm looking for a language exchange to improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Marathi&lt;br/&gt;Hindi</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>I am second year undergraduate student from Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>i am here for learn english and i help you wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Chinese (Mandarin)</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>Hello, I like to make friends around the world...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               native                                           language  \\\n",
       "0   1             Japanese  [{'language': 'English', 'level': 45, 'profici...   \n",
       "1   2  Spanish<br/>Catalan  [{'language': 'English', 'level': 45, 'profici...   \n",
       "2   4    Marathi<br/>Hindi  [{'language': 'English', 'level': 45, 'profici...   \n",
       "3   6              Italian  [{'language': 'English', 'level': 45, 'profici...   \n",
       "4   7   Chinese (Mandarin)  [{'language': 'English', 'level': 45, 'profici...   \n",
       "\n",
       "                                                text  \n",
       "0  Hi there:) I live in Tokyo. I have been learni...  \n",
       "1  I'm looking for a language exchange to improve...  \n",
       "2  I am second year undergraduate student from Mu...  \n",
       "3  i am here for learn english and i help you wit...  \n",
       "4  Hello, I like to make friends around the world...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset_polyg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19fa7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset_polyg.to_csv('./data/english_only_refined.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gram2",
   "language": "python",
   "name": "gram2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
