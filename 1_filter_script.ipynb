{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ee31e7",
   "metadata": {},
   "source": [
    "## 1. Select english sentences from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd8cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import spacy\n",
    "from langdetect import detect, DetectorFactory, detect_langs\n",
    "from polyglot.detect import Detector\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8b58c",
   "metadata": {},
   "source": [
    "### 1.1 Delete duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef5e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/dataset_cleand-1.csv\", names=['id', 'native', 'language', 'text'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7552114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x : ' '.join(x.splitlines()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdf2fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>native</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>[{'language': 'Spanish', 'level': 45, 'profici...</td>\n",
       "      <td>Je suis Monique 58 ans, de Metz dans le Nord-E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>Hi there:) I live in Tokyo. I have been learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish&lt;br/&gt;Catalan</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>Hi everyone!  I'm looking for a language excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>[{'language': 'German', 'level': 19.2857142857...</td>\n",
       "      <td>Wuieres aprender español? Yo te puedo ayudar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Marathi&lt;br/&gt;Hindi</td>\n",
       "      <td>[{'language': 'English', 'level': 45, 'profici...</td>\n",
       "      <td>I am second year undergraduate student from Mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               native                                           language  \\\n",
       "0   0               French  [{'language': 'Spanish', 'level': 45, 'profici...   \n",
       "1   1             Japanese  [{'language': 'English', 'level': 45, 'profici...   \n",
       "2   2  Spanish<br/>Catalan  [{'language': 'English', 'level': 45, 'profici...   \n",
       "3   3              Spanish  [{'language': 'German', 'level': 19.2857142857...   \n",
       "4   4    Marathi<br/>Hindi  [{'language': 'English', 'level': 45, 'profici...   \n",
       "\n",
       "                                                text  \n",
       "0  Je suis Monique 58 ans, de Metz dans le Nord-E...  \n",
       "1  Hi there:) I live in Tokyo. I have been learni...  \n",
       "2  Hi everyone!  I'm looking for a language excha...  \n",
       "3       Wuieres aprender español? Yo te puedo ayudar  \n",
       "4  I am second year undergraduate student from Mu...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1705263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Length: 82645\n",
      "New Length: \t28936\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates\n",
    "print(f'Orginal Length: {len(data)}')\n",
    "data = data.drop_duplicates(['native','language','text'])\n",
    "print(f'New Length: \\t{len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d92cd",
   "metadata": {},
   "source": [
    "### 1.2 use langdetect to extract english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f3d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable warning\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9944f888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▋                                                                 | 4055/28936 [00:29<02:46, 149.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weird entry\n",
      "id                                                       7324\n",
      "native                                                 Arabic\n",
      "language    [{'language': 'English', 'level': 45, 'profici...\n",
      "text        I love Japan♡♡♡♡♡♡♡ ♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡♡\n",
      "Name: 7324, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████▉                       | 20056/28936 [02:36<01:17, 114.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weird entry\n",
      "id                                                      58860\n",
      "native                                                Persian\n",
      "language    [{'language': 'English', 'level': 45, 'profici...\n",
      "text        ᴄᴏғғᴇᴇ ᴀᴅᴅɪᴄᴛ ◑ᴸᴼᴼᴷᴵᴺᴳ ᶠᴼᴿ ᴬ ᴳᴼᴼᴰ ᴮᴼᴼᴷ, ᵐᵒᵛⁱᵉ&...\n",
      "Name: 58860, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 28936/28936 [03:46<00:00, 127.54it/s]\n"
     ]
    }
   ],
   "source": [
    "new_data = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    entry = data.iloc[i]\n",
    "    try:\n",
    "        detected_langs = detect_langs(entry['text'])\n",
    "        for lang in detected_langs:\n",
    "            if lang.lang == 'en' and lang.prob > 0.5:\n",
    "                new_data.append(entry)\n",
    "                '''\n",
    "                print(entry['text'])\n",
    "                print(detected_langs)\n",
    "                '''\n",
    "                new_data[len(new_data)- 1][\"probabilities\"] = detected_langs \n",
    "                if lang.prob >= 0.99:\n",
    "                    new_data[len(new_data)- 1]['english_only'] = True\n",
    "                else:\n",
    "                    new_data[len(new_data) - 1]['english_only'] = False\n",
    "    except:\n",
    "        print(\"weird entry\")\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca2e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_copy = copy.deepcopy(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b9f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_df = pd.DataFrame(new_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ee7f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_df.to_csv(\"./data/english_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fafac1",
   "metadata": {},
   "source": [
    "### 1.3 use polyglot to further filter for english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905ccc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\envs\\gram2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67bf173c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x245959c1d50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e2676aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectorFactory.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ccf56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25706/25706 [11:13<00:00, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = pd.read_csv(\"./data/english_only.csv\", encoding='utf-8')\n",
    "dataset = csv_file[['id','native','language','text']]\n",
    "original_datset = copy.deepcopy(dataset)\n",
    "\n",
    "c = 0\n",
    "filtered_dataset = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(dataset['text']))):\n",
    "    splitted_text = tokenize.sent_tokenize(dataset['text'][i])\n",
    "    english_sent = []\n",
    "    for sent in splitted_text:\n",
    "        try:\n",
    "            langs = detect_langs(sent)\n",
    "            has_key = False\n",
    "            lang_index = 0\n",
    "            for l in range(len(langs)):\n",
    "                if langs[l].lang == \"en\":\n",
    "                    has_key = True\n",
    "                    lang_index = l\n",
    "                    break\n",
    "            if has_key and langs[lang_index].prob > 0.9:\n",
    "                english_sent.append(sent)\n",
    "        except:\n",
    "            pass\n",
    "    if len(english_sent) != 0:\n",
    "        dataset['text'][i] = \" \".join(english_sent)\n",
    "        # print(dataset['text'][i] ==  \" \".join(english_sent))\n",
    "        filtered_dataset = pd.concat([filtered_dataset, pd.DataFrame(dataset.iloc[[i]])])\n",
    "        c += 1  \n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0193a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset.to_csv('./data/english_only_refined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90224996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is reliable: True\n",
      "Language 1: name: Italian     code: it       confidence:  55.0 read bytes:   593\n",
      "Language 2: name: English     code: en       confidence:  44.0 read bytes:  1067\n",
      "Language 3: name: un          code: un       confidence:   0.0 read bytes:     0\n"
     ]
    }
   ],
   "source": [
    "# Test detector\n",
    "text_content = \"Hello. I'm looking for language partners for practice my English. I can help you with Italian of course. I wish to know new cultures. Ciao. Sto cercando dei partners linguistici per parlare inglese. Io posso aiutare a migliorare l'italiano. Desidero conoscere nuove culture.\"\n",
    "#print(detect_langs(text_content))\n",
    "#print(Detector(text_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d3efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25688\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset_polyg = pd.DataFrame()\n",
    "c = 0\n",
    "for i in range(len(dataset['text'])):\n",
    "    try: \n",
    "        langss = Detector(dataset['text'][i])\n",
    "        langs = langss.languages\n",
    "        if dataset['text'][i] == text_content:\n",
    "            print(langss)\n",
    "        has_key = False\n",
    "        lang_index = 0\n",
    "        for l in range(len(langs)):\n",
    "            if langs[l].code == \"en\":\n",
    "                has_key = True\n",
    "                lang_index = l\n",
    "                break\n",
    "        if has_key and langs[lang_index].confidence > 0.99:\n",
    "            filtered_dataset_polyg = pd.concat([filtered_dataset_polyg, pd.DataFrame(dataset.iloc[[i]])])\n",
    "            c += 1\n",
    "    except:\n",
    "        pass\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe7a8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                native  \\\n",
      "1         2   Spanish<br/>Catalan   \n",
      "4         6               Italian   \n",
      "9        23   Spanish<br/>Catalan   \n",
      "11       27               Spanish   \n",
      "13       34               Spanish   \n",
      "...     ...                   ...   \n",
      "3225  32988  Spanish<br/>Galician   \n",
      "3227  32990  Spanish<br/>Galician   \n",
      "3228  32991  Spanish<br/>Galician   \n",
      "3231  32995  Spanish<br/>Galician   \n",
      "3233  32997  Spanish<br/>Galician   \n",
      "\n",
      "                                               language  \\\n",
      "1     [{'language': 'English', 'level': 45, 'profici...   \n",
      "4     [{'language': 'English', 'level': 45, 'profici...   \n",
      "9     [{'language': 'Danish', 'level': 6.42857142857...   \n",
      "11    [{'language': 'English', 'level': 45, 'profici...   \n",
      "13    [{'language': 'English', 'level': 45, 'profici...   \n",
      "...                                                 ...   \n",
      "3225  [{'language': 'English', 'level': 45, 'profici...   \n",
      "3227  [{'language': 'English', 'level': 45, 'profici...   \n",
      "3228  [{'language': 'English', 'level': 45, 'profici...   \n",
      "3231  [{'language': 'Turkish', 'level': 6.4285714285...   \n",
      "3233  [{'language': 'English', 'level': 45, 'profici...   \n",
      "\n",
      "                                                   text  \n",
      "1     Hi everyone!\\nI'm looking for a language excha...  \n",
      "4     hi i'm antonio. i am here for learn english an...  \n",
      "9     I am from Barcelona and I speak Spanish and Ca...  \n",
      "11    Hola a todos mi nombre es Gilbert.. hoy es el ...  \n",
      "13    Hey, I'm interested in improving my English (I...  \n",
      "...                                                 ...  \n",
      "3225  Hi! I'm a Spanish girl who wants to learn Engl...  \n",
      "3227                                  Language exchange  \n",
      "3228  I would like to practise English because I wan...  \n",
      "3231  I want to learn Turkish and I can help with Sp...  \n",
      "3233  Hello!\\nI'm Noemí, I'm currently interested in...  \n",
      "\n",
      "[2197 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_dataset_polyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19fa7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset_polyg.to_csv('./data/only_english_polyg.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gram2",
   "language": "python",
   "name": "gram2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
